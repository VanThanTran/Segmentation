{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo_CFlp-ZnjB",
        "outputId": "882de4a5-659e-47f8-8157-b1cc0bbf128b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Okb9s07Zpn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee0cfa16-106d-4566-c07e-9de691792767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Unet\n",
            "data  Unet.ipynb\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/gdrive/MyDrive/Unet'\n",
        "! ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "https://github.com/zhixuhao/unet"
      ],
      "metadata": {
        "id": "XxXyJraoRIyj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9pGqEQqXnuW"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np \n",
        "import os\n",
        "import glob\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans"
      ],
      "metadata": {
        "id": "AvkeoJdRSEp7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XOqRZgGIXnuf"
      },
      "outputs": [],
      "source": [
        "Sky = [128,128,128]\n",
        "Building = [128,0,0]\n",
        "Pole = [192,192,128]\n",
        "Road = [128,64,128]\n",
        "Pavement = [60,40,222]\n",
        "Tree = [128,128,0]\n",
        "SignSymbol = [192,128,128]\n",
        "Fence = [64,64,128]\n",
        "Car = [64,0,128]\n",
        "Pedestrian = [64,64,0]\n",
        "Bicyclist = [0,128,192]\n",
        "Unlabelled = [0,0,0]\n",
        "\n",
        "COLOR_DICT = np.array([Sky, Building, Pole, Road, Pavement,\n",
        "                          Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist, Unlabelled])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "purb05wsXnug"
      },
      "outputs": [],
      "source": [
        "def adjustData(img,mask,flag_multi_class,num_class):\n",
        "    if(flag_multi_class):\n",
        "        img = img / 255\n",
        "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
        "        new_mask = np.zeros(mask.shape + (num_class,))\n",
        "        for i in range(num_class):\n",
        "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
        "            #index = np.where(mask == i)\n",
        "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
        "            #new_mask[index_mask] = 1\n",
        "            new_mask[mask == i,i] = 1\n",
        "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
        "        mask = new_mask\n",
        "    elif(np.max(img) > 1):\n",
        "        img = img / 255\n",
        "        mask = mask /255\n",
        "        mask[mask > 0.5] = 1\n",
        "        mask[mask <= 0.5] = 0\n",
        "    return (img,mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "juifJ4I_Xnui"
      },
      "outputs": [],
      "source": [
        "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
        "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
        "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n",
        "    '''\n",
        "    can generate image and mask at the same time\n",
        "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
        "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "    '''\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [image_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = image_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = image_save_prefix,\n",
        "        seed = seed)\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [mask_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = mask_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = mask_save_prefix,\n",
        "        seed = seed)\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    for (img,mask) in train_generator:\n",
        "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "        yield (img,mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "g9wXFiJfXnuj"
      },
      "outputs": [],
      "source": [
        "def testGenerator(test_path,num_image = 30,target_size = (256,256),flag_multi_class = False,as_gray = True):\n",
        "    for i in range(num_image):\n",
        "        img = io.imread(os.path.join(test_path,\"%d.png\"%i),as_gray = as_gray)\n",
        "        img = img / 255\n",
        "        img = trans.resize(img,target_size)\n",
        "        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
        "        img = np.reshape(img,(1,)+img.shape)\n",
        "        yield img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "20NHhe1_Xnuk"
      },
      "outputs": [],
      "source": [
        "def geneTrainNpy(image_path,mask_path,flag_multi_class = False,num_class = 2,image_prefix = \"image\",mask_prefix = \"mask\",image_as_gray = True,mask_as_gray = True):\n",
        "    image_name_arr = glob.glob(os.path.join(image_path,\"%s*.png\"%image_prefix))\n",
        "    image_arr = []\n",
        "    mask_arr = []\n",
        "    for index,item in enumerate(image_name_arr):\n",
        "        img = io.imread(item,as_gray = image_as_gray)\n",
        "        img = np.reshape(img,img.shape + (1,)) if image_as_gray else img\n",
        "        mask = io.imread(item.replace(image_path,mask_path).replace(image_prefix,mask_prefix),as_gray = mask_as_gray)\n",
        "        mask = np.reshape(mask,mask.shape + (1,)) if mask_as_gray else mask\n",
        "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "        image_arr.append(img)\n",
        "        mask_arr.append(mask)\n",
        "    image_arr = np.array(image_arr)\n",
        "    mask_arr = np.array(mask_arr)\n",
        "    return image_arr,mask_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OPOxsq_sXnum"
      },
      "outputs": [],
      "source": [
        "def labelVisualize(num_class,color_dict,img):\n",
        "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
        "    img_out = np.zeros(img.shape + (3,))\n",
        "    for i in range(num_class):\n",
        "        img_out[img == i,:] = color_dict[i]\n",
        "    return img_out / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ktdaPDRSXnun"
      },
      "outputs": [],
      "source": [
        "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
        "    for i,item in enumerate(npyfile):\n",
        "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
        "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BAvy2wMXnuo"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LkVrzo_ZXnuo"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "\n",
        "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs, conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    #model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel.load_weights(pretrained_weights)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg9_6iYVXnup"
      },
      "source": [
        "## Data augmentation \n",
        "\n",
        "In deep learning tasks, a lot of data is need to train DNN model, when the dataset is not big enough, data augmentation should be applied.\n",
        "\n",
        "keras.preprocessing.image.ImageDataGenerator is a data generator, which can feed the DNN with data like : (data,label), it can also do data augmentation at the same time.\n",
        "\n",
        "It is very convenient for us to use keras.preprocessing.image.ImageDataGenerator to do data augmentation by implement image rotation, shift, rescale and so on... see [keras documentation](https://keras.io/preprocessing/image/) for detail.\n",
        "\n",
        "For image segmentation tasks, the image and mask must be transformed **together!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzMGr5d2Xnup"
      },
      "source": [
        "## Define your data generator\n",
        "\n",
        "If you want to visualize your data augmentation result, set save_to_dir = your path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rgp5mYsPXnuq"
      },
      "outputs": [],
      "source": [
        "#if you don't want to do data augmentation, set data_gen_args as an empty dict.\n",
        "#data_gen_args = dict()\n",
        "\n",
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "myGenerator = trainGenerator(20,'data/membrane/train','image','label',data_gen_args,save_to_dir = \"data/membrane/train/aug\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEwBPu6qXnuq"
      },
      "source": [
        "## Visualize your data augmentation result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AhVX_pnXnur",
        "outputId": "ed33a456-cdeb-4e5a-c549-37be254e3f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30 images belonging to 1 classes.\n",
            "Found 30 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "#you will see 60 transformed images and their masks in data/membrane/train/aug\n",
        "num_batch = 3\n",
        "for i,batch in enumerate(myGenerator):\n",
        "    if(i >= num_batch):\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BifEiZtOXnur"
      },
      "source": [
        "## Create .npy data\n",
        "\n",
        "If your computer has enough memory, you can create npy files containing all your images and masks, and feed your DNN with them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3nLeZa3SXnur"
      },
      "outputs": [],
      "source": [
        "image_arr,mask_arr = geneTrainNpy(\"data/membrane/train/aug/\",\"data/membrane/train/aug/\")\n",
        "#np.save(\"data/image_arr.npy\",image_arr)\n",
        "#np.save(\"data/mask_arr.npy\",mask_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfrTtGd9Xnus"
      },
      "source": [
        "# TrainUnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50rDO95CXnus"
      },
      "source": [
        "### Train your Unet with membrane data\n",
        "Membrane data is in folder membrane/, it is a binary classification task.\n",
        "\n",
        "The input shape of image and mask are the same :(batch_size,rows,cols,channel = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfm3NQ9TXnus"
      },
      "source": [
        "### Train with data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Lqap382G34eT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_6COqcZXnut",
        "outputId": "96ecdcea-ea18-4e44-c722-f3a2978b8a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30 images belonging to 1 classes.\n",
            "Found 30 images belonging to 1 classes.\n",
            "Epoch 1/5\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.6673 - accuracy: 0.7812\n",
            "Epoch 00001: loss improved from inf to 0.66733, saving model to unet_membrane.hdf5\n",
            "2000/2000 [==============================] - 966s 482ms/step - loss: 0.6673 - accuracy: 0.7812\n",
            "Epoch 2/5\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.7813\n",
            "Epoch 00002: loss improved from 0.66733 to 0.62358, saving model to unet_membrane.hdf5\n",
            "2000/2000 [==============================] - 963s 482ms/step - loss: 0.6236 - accuracy: 0.7813\n",
            "Epoch 3/5\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.5896 - accuracy: 0.7814\n",
            "Epoch 00003: loss improved from 0.62358 to 0.58965, saving model to unet_membrane.hdf5\n",
            "2000/2000 [==============================] - 966s 483ms/step - loss: 0.5896 - accuracy: 0.7814\n",
            "Epoch 4/5\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.5640 - accuracy: 0.7815\n",
            "Epoch 00004: loss improved from 0.58965 to 0.56398, saving model to unet_membrane.hdf5\n",
            "2000/2000 [==============================] - 966s 483ms/step - loss: 0.5640 - accuracy: 0.7815\n",
            "Epoch 5/5\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.5458 - accuracy: 0.7815\n",
            "Epoch 00005: loss improved from 0.56398 to 0.54583, saving model to unet_membrane.hdf5\n",
            "2000/2000 [==============================] - 976s 488ms/step - loss: 0.5458 - accuracy: 0.7815\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f113034a450>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "myGene = trainGenerator(2,'data/membrane/train','image','label',data_gen_args,save_to_dir = None)\n",
        "model = unet()\n",
        "model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit_generator(myGene, steps_per_epoch=2000, epochs=5, callbacks=[model_checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BufS60PAXnuu"
      },
      "source": [
        "### Train with .npy file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "RpqtMFWrXnuu"
      },
      "outputs": [],
      "source": [
        "#imgs_train,imgs_mask_train = geneTrainNpy(\"data/membrane/train/aug/\",\"data/membrane/train/aug/\")\n",
        "#model.fit(imgs_train, imgs_mask_train, batch_size=2, nb_epoch=10, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVlunYqTXnuv"
      },
      "source": [
        "### Test your model and save predicted results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XLeKZcQDXnuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7443eef8-fede-45a4-a321-6fa2275ca368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 18s 517ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/0_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/1_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/2_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/3_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/4_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/5_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/6_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/7_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/8_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/9_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/10_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/11_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/12_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/13_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/14_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/15_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/16_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/17_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/18_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/19_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/20_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/21_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/22_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/23_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/24_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/25_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/26_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/27_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/28_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: data/membrane/test/29_predict.png is a low contrast image\n",
            "  after removing the cwd from sys.path.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        }
      ],
      "source": [
        "testGene = testGenerator(\"data/membrane/test\")\n",
        "model = unet()\n",
        "model.load_weights(\"unet_membrane.hdf5\")\n",
        "results = model.predict_generator(testGene,30,verbose=1)\n",
        "saveResult(\"data/membrane/test\",results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sZQk8ZPEQ9O7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Unet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}